{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture (0)\n",
    "height= cap.get(cv2.CAP_PROP_FRAME_HEIGHT)\n",
    "width= cap.get(cv2.CAP_PROP_FRAME_WIDTH)\n",
    "fps = cap.get (cv2.CAP_PROP_FPS)\n",
    "videoWriter = cv2.VideoWriter('leg_position1.mp4', cv2.VideoWriter_fourcc('P','I', 'M','1'), fps, (int(width), int(height)))\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    try:\n",
    "        cv2.imshow('leg_position1', frame)\n",
    "        videoWriter.write(frame)\n",
    "    except  Exception as e:\n",
    "        break\n",
    "    if cv2.waitKey (10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "videoWriter.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "landmarks = ['class']\n",
    "for val in range(1, 33+1):\n",
    "    landmarks += ['x{}'.format(val), 'y{}'.format(val), 'z{}'.format(val), 'v{}'.format(val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('feature_leg_position.csv', mode='w', newline='') as f:\n",
    "    csv_writer = csv.writer(f, delimiter=',',quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    csv_writer.writerow(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_landmark(results, action):\n",
    "    try:\n",
    "        keypoints = [action]  # Initialize the list with the action label\n",
    "\n",
    "        # Extract pose landmarks and append them to the keypoints list\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            keypoints.extend([landmark.x, landmark.y, landmark.z, landmark.visibility])\n",
    "\n",
    "        # Open the CSV file in 'a' (append) mode and write the keypoints\n",
    "        with open('feature_leg_position.csv', mode='a', newline='') as f:\n",
    "            csv_writer = csv.writer(f, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "            csv_writer.writerow(keypoints)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in export_landmark: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create a VideoCapture object to open the video file\n",
    "video_path = 'C:/Projects/FinalProject/excesise_proj/leg_exces/leg_position.mp4'\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# Check if the video file is opened successfully\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "# Initialize a variable to keep track of the current pose\n",
    "current_pose = None\n",
    "\n",
    "# Create a dictionary to map keys to pose labels\n",
    "key_to_pose = {\n",
    "    ord('a'): 'small',\n",
    "    ord('s'): 'mid',\n",
    "    ord('d'): 'wide'\n",
    "}\n",
    "\n",
    "# Main processing loop\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        if not ret:\n",
    "            break  # Exit the loop when there are no more frames\n",
    "\n",
    "        # Convert frame to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        # Perform pose detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Convert back to BGR for rendering\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Draw landmarks and lines on the frame\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2))\n",
    "\n",
    "        # Check for key presses and export landmarks\n",
    "        key = cv2.waitKey(1)\n",
    "        if key in key_to_pose:\n",
    "            current_pose = key_to_pose[key]\n",
    "            #print(current_pose)\n",
    "            export_landmark(results, current_pose)\n",
    "\n",
    "        # Display the frame\n",
    "        cv2.imshow('webcam feed', image)\n",
    "\n",
    "        # Check for 'q' key to quit\n",
    "        if key == ord('q'):\n",
    "            break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Projects/FinalProject/excesise_proj/leg_exces/feature_leg_position.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>z1</th>\n",
       "      <th>v1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>z2</th>\n",
       "      <th>v2</th>\n",
       "      <th>x3</th>\n",
       "      <th>...</th>\n",
       "      <th>z31</th>\n",
       "      <th>v31</th>\n",
       "      <th>x32</th>\n",
       "      <th>y32</th>\n",
       "      <th>z32</th>\n",
       "      <th>v32</th>\n",
       "      <th>x33</th>\n",
       "      <th>y33</th>\n",
       "      <th>z33</th>\n",
       "      <th>v33</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>wide</td>\n",
       "      <td>0.655026</td>\n",
       "      <td>0.045260</td>\n",
       "      <td>-0.589442</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.664644</td>\n",
       "      <td>0.027130</td>\n",
       "      <td>-0.575842</td>\n",
       "      <td>0.999960</td>\n",
       "      <td>0.669763</td>\n",
       "      <td>...</td>\n",
       "      <td>0.182368</td>\n",
       "      <td>0.737731</td>\n",
       "      <td>0.743783</td>\n",
       "      <td>0.880988</td>\n",
       "      <td>-0.017547</td>\n",
       "      <td>0.961876</td>\n",
       "      <td>0.554220</td>\n",
       "      <td>0.869039</td>\n",
       "      <td>0.003634</td>\n",
       "      <td>0.954608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wide</td>\n",
       "      <td>0.663030</td>\n",
       "      <td>0.048134</td>\n",
       "      <td>-0.624495</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.672878</td>\n",
       "      <td>0.028771</td>\n",
       "      <td>-0.608860</td>\n",
       "      <td>0.999963</td>\n",
       "      <td>0.678245</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247037</td>\n",
       "      <td>0.735461</td>\n",
       "      <td>0.731904</td>\n",
       "      <td>0.880210</td>\n",
       "      <td>0.051311</td>\n",
       "      <td>0.957008</td>\n",
       "      <td>0.536151</td>\n",
       "      <td>0.859882</td>\n",
       "      <td>0.075392</td>\n",
       "      <td>0.952495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>wide</td>\n",
       "      <td>0.661599</td>\n",
       "      <td>0.049464</td>\n",
       "      <td>-0.633611</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.671619</td>\n",
       "      <td>0.029611</td>\n",
       "      <td>-0.616365</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.676916</td>\n",
       "      <td>...</td>\n",
       "      <td>0.260525</td>\n",
       "      <td>0.761741</td>\n",
       "      <td>0.736948</td>\n",
       "      <td>0.880240</td>\n",
       "      <td>0.040138</td>\n",
       "      <td>0.960436</td>\n",
       "      <td>0.542046</td>\n",
       "      <td>0.853574</td>\n",
       "      <td>0.091661</td>\n",
       "      <td>0.956912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wide</td>\n",
       "      <td>0.661172</td>\n",
       "      <td>0.050654</td>\n",
       "      <td>-0.618133</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.671022</td>\n",
       "      <td>0.030381</td>\n",
       "      <td>-0.603611</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.676143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.241067</td>\n",
       "      <td>0.765429</td>\n",
       "      <td>0.733758</td>\n",
       "      <td>0.880682</td>\n",
       "      <td>0.046070</td>\n",
       "      <td>0.960120</td>\n",
       "      <td>0.548025</td>\n",
       "      <td>0.862142</td>\n",
       "      <td>0.057138</td>\n",
       "      <td>0.956754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wide</td>\n",
       "      <td>0.660935</td>\n",
       "      <td>0.049306</td>\n",
       "      <td>-0.558362</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.670924</td>\n",
       "      <td>0.030153</td>\n",
       "      <td>-0.543855</td>\n",
       "      <td>0.999962</td>\n",
       "      <td>0.675930</td>\n",
       "      <td>...</td>\n",
       "      <td>0.171301</td>\n",
       "      <td>0.749507</td>\n",
       "      <td>0.733039</td>\n",
       "      <td>0.880386</td>\n",
       "      <td>-0.025799</td>\n",
       "      <td>0.954908</td>\n",
       "      <td>0.542212</td>\n",
       "      <td>0.854872</td>\n",
       "      <td>-0.007017</td>\n",
       "      <td>0.952080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>small</td>\n",
       "      <td>0.687472</td>\n",
       "      <td>0.033901</td>\n",
       "      <td>-0.506831</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.697686</td>\n",
       "      <td>0.016992</td>\n",
       "      <td>-0.492989</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>0.702554</td>\n",
       "      <td>...</td>\n",
       "      <td>0.189015</td>\n",
       "      <td>0.630392</td>\n",
       "      <td>0.686979</td>\n",
       "      <td>0.864268</td>\n",
       "      <td>0.044717</td>\n",
       "      <td>0.942550</td>\n",
       "      <td>0.631070</td>\n",
       "      <td>0.851062</td>\n",
       "      <td>0.036421</td>\n",
       "      <td>0.921771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>small</td>\n",
       "      <td>0.687045</td>\n",
       "      <td>0.034629</td>\n",
       "      <td>-0.445158</td>\n",
       "      <td>0.999988</td>\n",
       "      <td>0.696739</td>\n",
       "      <td>0.017472</td>\n",
       "      <td>-0.435109</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.701611</td>\n",
       "      <td>...</td>\n",
       "      <td>0.139999</td>\n",
       "      <td>0.625401</td>\n",
       "      <td>0.687378</td>\n",
       "      <td>0.861439</td>\n",
       "      <td>0.009014</td>\n",
       "      <td>0.941465</td>\n",
       "      <td>0.631360</td>\n",
       "      <td>0.848404</td>\n",
       "      <td>0.008940</td>\n",
       "      <td>0.920657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>small</td>\n",
       "      <td>0.686708</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>-0.534402</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.696151</td>\n",
       "      <td>0.013826</td>\n",
       "      <td>-0.515486</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.701136</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188720</td>\n",
       "      <td>0.626154</td>\n",
       "      <td>0.686726</td>\n",
       "      <td>0.863504</td>\n",
       "      <td>0.048705</td>\n",
       "      <td>0.941926</td>\n",
       "      <td>0.635794</td>\n",
       "      <td>0.846513</td>\n",
       "      <td>0.036890</td>\n",
       "      <td>0.921364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>small</td>\n",
       "      <td>0.684887</td>\n",
       "      <td>0.033988</td>\n",
       "      <td>-0.559904</td>\n",
       "      <td>0.999987</td>\n",
       "      <td>0.695049</td>\n",
       "      <td>0.016111</td>\n",
       "      <td>-0.548919</td>\n",
       "      <td>0.999949</td>\n",
       "      <td>0.700176</td>\n",
       "      <td>...</td>\n",
       "      <td>0.212547</td>\n",
       "      <td>0.627553</td>\n",
       "      <td>0.685103</td>\n",
       "      <td>0.863187</td>\n",
       "      <td>0.065961</td>\n",
       "      <td>0.941352</td>\n",
       "      <td>0.636388</td>\n",
       "      <td>0.854149</td>\n",
       "      <td>0.060205</td>\n",
       "      <td>0.921446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>small</td>\n",
       "      <td>0.684083</td>\n",
       "      <td>0.040620</td>\n",
       "      <td>-0.337102</td>\n",
       "      <td>0.999989</td>\n",
       "      <td>0.693907</td>\n",
       "      <td>0.021657</td>\n",
       "      <td>-0.332781</td>\n",
       "      <td>0.999955</td>\n",
       "      <td>0.698918</td>\n",
       "      <td>...</td>\n",
       "      <td>0.076527</td>\n",
       "      <td>0.657774</td>\n",
       "      <td>0.716077</td>\n",
       "      <td>0.877239</td>\n",
       "      <td>-0.018717</td>\n",
       "      <td>0.947005</td>\n",
       "      <td>0.635844</td>\n",
       "      <td>0.867814</td>\n",
       "      <td>-0.028673</td>\n",
       "      <td>0.931443</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>523 rows × 133 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     class        x1        y1        z1        v1        x2        y2  \\\n",
       "0     wide  0.655026  0.045260 -0.589442  0.999983  0.664644  0.027130   \n",
       "1     wide  0.663030  0.048134 -0.624495  0.999986  0.672878  0.028771   \n",
       "2     wide  0.661599  0.049464 -0.633611  0.999988  0.671619  0.029611   \n",
       "3     wide  0.661172  0.050654 -0.618133  0.999989  0.671022  0.030381   \n",
       "4     wide  0.660935  0.049306 -0.558362  0.999988  0.670924  0.030153   \n",
       "..     ...       ...       ...       ...       ...       ...       ...   \n",
       "518  small  0.687472  0.033901 -0.506831  0.999989  0.697686  0.016992   \n",
       "519  small  0.687045  0.034629 -0.445158  0.999988  0.696739  0.017472   \n",
       "520  small  0.686708  0.028670 -0.534402  0.999987  0.696151  0.013826   \n",
       "521  small  0.684887  0.033988 -0.559904  0.999987  0.695049  0.016111   \n",
       "522  small  0.684083  0.040620 -0.337102  0.999989  0.693907  0.021657   \n",
       "\n",
       "           z2        v2        x3  ...       z31       v31       x32  \\\n",
       "0   -0.575842  0.999960  0.669763  ...  0.182368  0.737731  0.743783   \n",
       "1   -0.608860  0.999963  0.678245  ...  0.247037  0.735461  0.731904   \n",
       "2   -0.616365  0.999967  0.676916  ...  0.260525  0.761741  0.736948   \n",
       "3   -0.603611  0.999967  0.676143  ...  0.241067  0.765429  0.733758   \n",
       "4   -0.543855  0.999962  0.675930  ...  0.171301  0.749507  0.733039   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "518 -0.492989  0.999959  0.702554  ...  0.189015  0.630392  0.686979   \n",
       "519 -0.435109  0.999955  0.701611  ...  0.139999  0.625401  0.687378   \n",
       "520 -0.515486  0.999951  0.701136  ...  0.188720  0.626154  0.686726   \n",
       "521 -0.548919  0.999949  0.700176  ...  0.212547  0.627553  0.685103   \n",
       "522 -0.332781  0.999955  0.698918  ...  0.076527  0.657774  0.716077   \n",
       "\n",
       "          y32       z32       v32       x33       y33       z33       v33  \n",
       "0    0.880988 -0.017547  0.961876  0.554220  0.869039  0.003634  0.954608  \n",
       "1    0.880210  0.051311  0.957008  0.536151  0.859882  0.075392  0.952495  \n",
       "2    0.880240  0.040138  0.960436  0.542046  0.853574  0.091661  0.956912  \n",
       "3    0.880682  0.046070  0.960120  0.548025  0.862142  0.057138  0.956754  \n",
       "4    0.880386 -0.025799  0.954908  0.542212  0.854872 -0.007017  0.952080  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "518  0.864268  0.044717  0.942550  0.631070  0.851062  0.036421  0.921771  \n",
       "519  0.861439  0.009014  0.941465  0.631360  0.848404  0.008940  0.920657  \n",
       "520  0.863504  0.048705  0.941926  0.635794  0.846513  0.036890  0.921364  \n",
       "521  0.863187  0.065961  0.941352  0.636388  0.854149  0.060205  0.921446  \n",
       "522  0.877239 -0.018717  0.947005  0.635844  0.867814 -0.028673  0.931443  \n",
       "\n",
       "[523 rows x 133 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df.drop('class', axis=1)\n",
    "y=df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3,random_state=1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "scaler = StandardScaler()\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-13 {color: black;background-color: white;}#sk-container-id-13 pre{padding: 0;}#sk-container-id-13 div.sk-toggleable {background-color: white;}#sk-container-id-13 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-13 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-13 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-13 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-13 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-13 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-13 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-13 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-13 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-13 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-13 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-13 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-13 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-13 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-13 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-13 div.sk-item {position: relative;z-index: 1;}#sk-container-id-13 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-13 div.sk-item::before, #sk-container-id-13 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-13 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-13 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-13 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-13 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-13 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-13 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-13 div.sk-label-container {text-align: center;}#sk-container-id-13 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-13 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-13\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>KNeighborsClassifier(n_neighbors=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" checked><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">KNeighborsClassifier</label><div class=\"sk-toggleable__content\"><pre>KNeighborsClassifier(n_neighbors=3)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=3)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=3)\n",
    "model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.90\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         mid       0.92      0.87      0.89        75\n",
      "       small       0.87      0.95      0.91        42\n",
      "        wide       0.90      0.90      0.90        40\n",
      "\n",
      "    accuracy                           0.90       157\n",
      "   macro avg       0.90      0.91      0.90       157\n",
      "weighted avg       0.90      0.90      0.90       157\n",
      "\n",
      "[[65  6  4]\n",
      " [ 2 40  0]\n",
      " [ 4  0 36]]\n"
     ]
    }
   ],
   "source": [
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as C:/Users/shana/OneDrive/Desktop/excesise_proj/leg_exces/leg_position_knn.joblib\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "# Save the model to a file\n",
    "\n",
    "model_file = 'C:/Projects/FinalProject/excesise_proj/leg_exces/leg_position_knn.joblib'\n",
    "with open(model_file, 'wb') as file:\n",
    "    pickle.dump(model, file)\n",
    "print(f\"Model saved as {model_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C:/Users/shana/OneDrive/Desktop/excesise_proj/leg_exces/leg_position_V3.joblib']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "model_file = 'C:/Projects/FinalProject/excesise_proj/leg_exces/leg_position_V3.joblib'\n",
    "dump(model, model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n",
      "Error: 'NoneType' object has no attribute 'landmark'\n"
     ]
    }
   ],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "state = ''\n",
    "\n",
    "# Mapping of classes to actions\n",
    "class_to_action = {\n",
    "    'nutral': 'nutral',\n",
    "    'mid': 'mid',\n",
    "    'wide': 'wide'\n",
    "}\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        try:\n",
    "            row = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "            x = pd.DataFrame([row], columns=landmarks[1:])\n",
    "            state_class = model.predict(x)[0]\n",
    "            state_prob = model.predict_proba(x)[0]\n",
    "            #print(f\"State: {state_class}, State Prob: {state_prob}\")\n",
    "\n",
    "            if state_class in class_to_action and state_prob[state_prob.argmax()] >= 0.7:\n",
    "                state = class_to_action[state_class]\n",
    "\n",
    "            cv2.rectangle(image, (0,0), (250,60), (245,117,16), -1)\n",
    "\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(image, state_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(image, str(round(state_prob[np.argmax(state_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        cv2.imshow('webcam feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = load(model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_loaded = loaded_model.predict(x_test)\n",
    "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
    "print(f'Loaded Model Accuracy: {accuracy_loaded:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(0)\n",
    "state = ''\n",
    "\n",
    "# Mapping of classes to actions\n",
    "class_to_action = {\n",
    "    'nutral': 'nutral',\n",
    "    'mid': 'mid',\n",
    "    'wide': 'wide'\n",
    "}\n",
    "\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "\n",
    "        # Make detection\n",
    "        results = pose.process(image)\n",
    "\n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS,\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 117, 66), thickness=2, circle_radius=2),\n",
    "                                  mp_drawing.DrawingSpec(color=(245, 66, 230), thickness=2, circle_radius=2)\n",
    "                                  )\n",
    "\n",
    "        try:\n",
    "            row = np.array([[res.x, res.y, res.z, res.visibility] for res in results.pose_landmarks.landmark]).flatten().tolist()\n",
    "            x = pd.DataFrame([row], columns=landmarks[1:])\n",
    "            state_class = loaded_model.predict(x)[0]\n",
    "            state_prob = loaded_model.predict_proba(x)[0]\n",
    "            #print(f\"State: {state_class}, State Prob: {state_prob}\")\n",
    "\n",
    "            if state_class in class_to_action and state_prob[state_prob.argmax()] >= 0.7:\n",
    "                state = class_to_action[state_class]\n",
    "\n",
    "            cv2.rectangle(image, (0,0), (250,60), (245,117,16), -1)\n",
    "\n",
    "            cv2.putText(image, 'CLASS'\n",
    "                        , (95,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(image, state_class.split(' ')[0]\n",
    "                        , (90,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(image, 'PROB'\n",
    "                        , (15,12), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0,0,0), 1, cv2.LINE_AA)\n",
    "            \n",
    "            cv2.putText(image, str(round(state_prob[np.argmax(state_prob)],2))\n",
    "                        , (10,40), cv2.FONT_HERSHEY_SIMPLEX, 1, (255,255,255), 2, cv2.LINE_AA)\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "        cv2.imshow('webcam feed', image)\n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
